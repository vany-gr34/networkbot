{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb63afc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976caf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "os.chdir(r\"d:\\networkbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fd292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\networkbot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd519c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into chunks \n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader,TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_files(data):\n",
    "    \n",
    "    pdf_loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    pdf_documents = pdf_loader.load()\n",
    "\n",
    "   \n",
    "    txt_loader = DirectoryLoader(data, glob=\"*.txt\", loader_cls=TextLoader)\n",
    "    txt_documents = txt_loader.load()\n",
    "\n",
    "\n",
    "    documents = pdf_documents + txt_documents\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761eb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data={\n",
    "    'general':\"/Data/general\",\n",
    "    'security':\"Data/security\",\n",
    "    'monitoring':\"Data/monitoring\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac8a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a8ea4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86654bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#text_chunks=text_split(extracted_data)\n",
    "#print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad6a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "275c323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fa50539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win 10\\AppData\\Local\\Temp\\ipykernel_11776\\1196424635.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\win 10\\miniconda3\\envs\\chatbot1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b1d957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))\n",
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900dca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f23e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54644def",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"bot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c86f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "355dd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x199c03fd570>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c27fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9187455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is switch?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce0240a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9b4a8d5f-79e7-414f-99c0-4dad24984c4d', metadata={'author': 'Peter L Dordal', 'creationdate': '2023-07-20T19:58:26-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T19:58:26-05:00', 'page': 60.0, 'page_label': '49', 'producer': 'pdfTeX-1.40.20', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019/Debian) kpathsea version 6.3.1', 'source': 'Data\\\\ComputerNetworks1.pdf', 'subject': '', 'title': 'An Introduction to Computer Networks', 'total_pages': 967.0, 'trapped': '/False'}, page_content='other ports.\\nOriginally, switches were seen as providing interconnection (“bridging”) between separate physical Ether-\\nnets; a switch for such a purpose needed just two ports. Later, a switched Ethernet was seen as one large\\n“virtual” Ethernet, composed of smaller collision domains. Although the term “switch” is now much more\\ncommon than “bridge”, the latter is still in use, particularly by the IEEE. For some, a switch is a bridge with'),\n",
       " Document(id='6a9f91d3-a4c2-4118-92df-95a4974c5ac4', metadata={'author': 'Peter L Dordal', 'creationdate': '2023-07-20T19:58:26-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T19:58:26-05:00', 'page': 60.0, 'page_label': '49', 'producer': 'pdfTeX-1.40.20', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019/Debian) kpathsea version 6.3.1', 'source': 'Data\\\\ComputerNetworks1.pdf', 'subject': '', 'title': 'An Introduction to Computer Networks', 'total_pages': 967.0, 'trapped': '/False'}, page_content='other ports.\\nOriginally, switches were seen as providing interconnection (“bridging”) between separate physical Ether-\\nnets; a switch for such a purpose needed just two ports. Later, a switched Ethernet was seen as one large\\n“virtual” Ethernet, composed of smaller collision domains. Although the term “switch” is now much more\\ncommon than “bridge”, the latter is still in use, particularly by the IEEE. For some, a switch is a bridge with'),\n",
       " Document(id='65adb665-7d7b-4c22-9f8a-ec2604f4d0e8', metadata={'author': 'Peter L Dordal', 'creationdate': '2023-07-20T19:58:26-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-07-20T19:58:26-05:00', 'page': 229.0, 'page_label': '218', 'producer': 'pdfTeX-1.40.20', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019/Debian) kpathsea version 6.3.1', 'source': 'Data\\\\ComputerNetworks1.pdf', 'subject': '', 'title': 'An Introduction to Computer Networks', 'total_pages': 967.0, 'trapped': '/False'}, page_content='forwarded throughout a switched network; they do not, however, pass to different subnets. Second, LAN\\nnetworks do not like redundant links (that is, loops); while one can rely on the spanning-tree algorithm to\\neliminate these, that algorithm too becomes less efﬁcient at larger scales.\\nThe rise of software-deﬁned networking ( 3.4 Software-Deﬁned Networking ) has blurred the distinction\\nbetween routing and switching. The term “Layer 3 switch” is sometimes used to describe routers that')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a31e6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(api_key=\"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\", model=\"llama3-70b-8192\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a7b5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66e985bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e108a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCP/IP is not explicitly defined in the provided context. However, TCP (Transmission Control Protocol) is a protocol that is part of the TCP/IP suite, which is a set of communication protocols used to interconnect devices on the internet.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is tcp/ip?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaming(selected_expert):\n",
    "    if selected_expert==\"monitoring\":\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"general\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    "        question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "        rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
