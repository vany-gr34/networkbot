mot_cl√©,post_et_reponses
firewall best practices,"been going through a bunch of articles and uptime docs but couldnt find much on this hoping someone heres been through it. so im in telco, and weve got a few tocs technical operations centers. regular officetype setups where people work 95 , different sector business, operations, finance, etc. some of these are located right next to or within our data center buildings. im trying to figure out how to secure the actual dc zones or toc from these personnel, without messing up operations. thinking of stuff like zoning physical barriers mfa or biometric access redundant hvac just for dc cctv badgeonly access anyone here knows if there are any frameworksguidelines for me to set the requirements? would love to hear your thoughts. || have you looked into iso 27001? this covers operational security. some others from perplexity are nist sp 80053 ssae 16isae 3402"
firewall best practices,"ive got a small enterprise network i am deploying.. a pair of c9336cfx2e running nxos 10.35 in vpc domain. since this is for the enterprise not an msp, i really see no advantage to running multiple vrfs, my preference is to keep things simple... although i have gone wthe best practice of keeping the vpc peerkeepalive on the management vrf by itself. what i really want to talk about is all of these mentions of having dedicated layer2 and dedicated layer3 links. i much prefer to have a nice fat 400gig vpc peer link on which i have the peergateway, layer3 peerrouter, fastconvergence, and autorecovery features enabled. the use case is for hpc and vdi all deployed into a single cabinet with a pure storage with file services... were looking at omnissa for vdi. but getting back to having dedicated layer3 which is often cited as a best practice the only advantages i see are to prevent routing issues during potential misconfigurations, and potentially faster recovery in certain failure scenarios.. ignoring misconfigurations lets assume they wont happen changes will be very minimal once this is up and running what am i missing, why is it a bp to add dedicated layer3 links? i am going to be running ospf in the network core on the same switches that host the vpc domain... why cant i just let that all run over the same vpc peerlink? please tell me what im missing here... not to mention if you look at the table on this link there are asterisks and other symbols next to l2 link and l3 link for different topological routing adjacencies ie. future support may be limited with dedicated l2l3 links if the environment expands || love this, youre clearly thinking this through. im a var and heres kinda what ive seen from customers and cisco ses in similar vpc builds dedicated layer 3 links give you fault isolation. if your vpc peerlink gets congested, flaps, or hits errors, you dont want routing protocols or northsouth traffic tied up in that. vpc peerlinks are really meant for eastwest l2 traffic and vpc control plane sync. when you push routing adjacencies and l3 over them, especially with ospf, recovery behavior can get messy under failure conditions. ciscos own best practice is to keep the vpc peerlink clean, and use a separate routed link often via the same pair of switches, sure for l3 adjacencies like ospf or bgp. helps avoid weird dependencies during convergence events. your setup with 400g and all the vpc enhancements sounds solid. if your use case is predictable and failure domains are small, it may still work fine. but if you anticipate growth or changes vdi scaleout, separation is worth it. dm me if you need more helpsupport! || we just use a virtual l3 link using svis 30. you want l3 connectivity between the n9ks right? || maybe it was before being able to use layer3 peerrouter? im on a big peerlink vpc like your config and its fine with vpc, ospf, bgp, multicast and without peerrouter it wouldnt be possible or half the traffic would just black hole."
firewall best practices,"hey , i could use some help figuring out the best spot to drop in a ips in a network im working on where weve got multiple sites connected via sdwan over mpls, back to our central data center. the traffic path is basically branch sites hub routers wan firewall internal network were thinking of putting the ips in l2 transparent mode between the hub routers and the wan firewall, so we can inspect traffic coming in from the field before it hits anything important. couple of things im unsure about is this the right spot to put the ips? any issues with sdwan tunnels ipsecgre being broken or not inspected properly in this position? would you recommend placing it somewhere else? anyone have experience using tippingpoint specifically in sdwan setups? appreciate any advice, war stories, or gotchas youve run into. thanks! || if youre not planning on breaking open tls to inspect it and dealing with all of the associated fun of managing that process, id ask your security folks what they hope to actually see on the wire with ips in 2025. || does your firewall not have ips functionality already? if youre using an ngfw like a palo alto or fortinet, theyre already performing threat prevention, sandboxing, malware detection, etc. etc. if youre purchased those subscriptions. the benefits are probably quite low if youre adding another ips platform sitting adjacent to your firewall. || it depends on what threats scenarios you will be using the ips for. if you are worried that someone will break into your ipsec, and s8mple acl wont be enough, then you will need the ips infront of the sdwan router. if you are worried about internal users breaking in through your wan network, then why not enabling ips on your firewall?"
firewall best practices,"i have been searching to try and find an answer but i keep coming up blank. so any thoughts will be appreciated. i have asked both dell software support and dell networking but neither of them has an answer. the networking group does not have any best practice for how to setup the switch for use with hyperv to best take advantage of vlt networking. i have dell pro support plus on all my equipment. the dell network team says it is a hyperv question on how they want it setup. the dell software support says this is a dell networking question and they both think they are independent. i am running hyperv and using powershell to create a virtual set using hypervport for load balancing. i have a 3 node cluster running 75 virtual servers on the cluster set does not support lacp my hyperv host are connected to two dell switches that are running dell os10 setup with vlt all servers are the same the following is an example of one server 1 connected to switch 1 with 2 ports connected to switch 2 with 2 ports all 4 ports on server 1 are in a single set virtual switch i have added host os, cluster network and backup network as virtual nics off the main set so the os sees the host os, cluster network and backup network iscsi is on dedicated nics that are not part of set and are using mpio with a nic connected to each switch. to best handle efficient routing of traffic between virtual servers and fast notification of down link events what is the preferred method of setup from the switch side of the equation. i run 10 rds session host servers using fslogix for profile storage so network latency matters to give my users a good experience. option 1 do nothing on the ports at the switch level. this requires that all traffic be routed and can put a lot of traffic on the backplane of the vlti interface between the switches because it does not optimize traffic. option 2 setup a port channel with lacp set to static. this will communicate to the vlt switches the group of ports are together for routing and notification and not creating loops. my understanding is this also helps with routing of traffic and notification during loss of 1 switch i.e. maintenance windows for switch. option 3 doing an lbfo nic team that does support lacp then apply the set switch to the team was an option but is not the recommended method from microsoft. also this only gives you one vmmq because the set only sees one nic so it cannot take advantaged of all 4 nics for offloading traffic. option 4 some other method best load balancing for vlt switches vnic is the guest nic and pnic is the physical nic currently all my virtual servers have 1 vnic best practice from microsoft is to use hypervport for all 10gb or faster nics. option 1 hypervport this basically sets a vm to a card the distribution is done by the os and just load them up in a round robin fashion. this vnic1 connects to pnic1 vnic2 connects to pnic2 vnic3 connects to pnic3 vnic4 connects to pnic4 vnic5 connects to pnic1 etc. option 2 dynamic the traffic from vnics gets send out on all 4 pnics in round robin but only one pnic can receive traffic. i do not know if it the process is smart enough to know that it is talking with a vm guest that also on the same switch then it would only send out on the pnics that are connected with that same switch. this could generate a lot of traffic on the vlti backplane if half of the packets are coming from the other switch. i must be over thinking this which is not unusual for me but the lack of documentation is pretty astounding considering this technology has been around for 10 years. || vlt seems to be the dell version of vpc. dont do anything on the switches, set is switch independent and works fine as is. || yep. no fancy config on switches. how load is balanced and bandwidth utilized depends on if the port is set to dynamic or hyper v. you should probably use hyperv port for your vms. refer to the guide from lenovo below which details set requirements and setup for hyperconverged. it is the same for converged, but includes rdma setup. microsoft also has documentation on this on learn.microsoft.com. || yes you dont really do any lag or anything. just present the ports and set itself will handle it."
firewall best practices,"i have a customer who we did a network design for just over a year ago. we talked them through all the pros and cons as part of the design process and they selected to terminate all the vlans onto their cisco switches and then just have a layer 3 transit up to the firewall. this firewall was easy to spec as it was essentially just a case of how big are your internet pipes, how much might they grow over the next 56 years. boom there is a firewall. we are now 12 months layer and they are saying we want to terminate all the vlans and they have a lot, and want more onto the firewall. i agree this is a superior and potentially more secure design but i suspect if we do this it will just overload the firewall as it just wasnt speced for that use case. the customer, and rightfully so, is saying give us some figures to backup that statement. that got me thinking.... what is the best way to do this? my initial thought process is put netflow in on the core switch and look at the traffic levels between the various vlans. we could also monitor the traffic levels on the svis its a cisco core switch and see what traffic levels they get. currently the customer is using prtg but is there some other tools that could give us better reporting? but what does reddit think? what have i missed? what else could i consider? ||  || you dont say anything about the fw capabilities. its very difficult to answer the question in the title if you dont specify the firewall itself. and i do agree with other comments it all depends what you want to do with the traffic when it hits the firewall. do you just want to do regular l4 filtering or are they going with something like l7 filtering appid with pa, ssl decryption? are you going to employ security profiles to filter ew traffic as well? is the firewall doing any ipsec tunneling or ravpn? basically, its not just the amount of traffic, its also what youre going to do with it. newer fortigates and pa series starting with 400 series are small beasts and can handle a lot of abuse of course, the more you need, the higher you go on the ladder when speccing the fw as well. as for routing, i disagree with some of the comments unless youre talking about very specific routing usually reserved for datacenters, firewalls are more than capable of doing it, at least major vendors in the field are. if youre talking about just intervlan routing, then double that. ive been in networking field for past 20 years, last 10 years mostly security engineering firewalls and unless im working with a very specific type of a company that absolutely needs to have line speed for intervlan traffic, all vlans are terminated on the firewall, no exception im done with the days of 2010 years ago when i was trying to figure out which acl on a switch is blocking something. || group networks inside a vrf and use the firewall as the gateway. this reduces the number of vlans on the firewall and allows east west between like networks with minimal security concern."
firewall best practices,"hi all, is it possible to implement vpc with the following design ? if not, whats the best practice to do ? should i put a switch in between nexus to checkpoint firewall ? thanks vpc aside, our goal is to connect 1 nexus to 2 firewalls properly with our current limited legacy equipments. the requirements firewall cluster is configured vrrp connected to 1 nexus we dont mind to add 1 switch in between nexus and firewalls if vpc is not appropriate. || thats not vpc. vpc is when one device like a fw is connected to two nexus switches. i dont believe checkpoint fws can connect like that. each connection to the switch will be a unique link. best practice is to have two switches. the next hop for the fws would be the nexus switch, and the next hop for the nexus switch would be the ha ip on the fws vrrp?. if it is vrrp, youve got the addressing wrong on the fws. || im trying to understand your topology. if you want to run vrrp, why are the firewalls connected to each other? to be honest, i would scrap the vrrp setup and just run ha between the fw and run vpc lacp from the nexus switch to fws. for best practise, it is better to run two switches and run it like this. both designs are valid, alternative 2 gives you extra redundancy. if youre limited with one nexus, then i would not run a normal lacp on the nexus, i would prepare it with vpc config in case another switch will be added in the future, that way, you do not need to any reconfiguration between the nexuses and the firewalls, just add an another vpc id to the new nexus connecting to the firewalls and run vpc peerlink between the nexus switches. and yes, you can actually run vpc with one nexus switch connected to two firewalls. it will not really do that much but it is definitely possible to do it. || you dont do vpc with a single nexus switch. pretend its any other switch."
firewall best practices,"hoping to get everyones input. what do you believe is the best practice for printer ips static dhcp reservation or manually configured static ip on device? poll background at a place where the old adage if it aint broke, dont change lives strong. this includes essentially all 100 printers being set with manually configured static ips on the device only, no dhcp record. the reasoning is if dhcp goes down, it still works. ive been in it for 20 years, and and i cant recall a time when that happened, plus if dhcp goes down, theres something a lot bigger wrong. we have an ipdhcp management site for our network as were part of a much larger corporation that uses it, and i want to make the push to get our location using that and static dhcp reservations instead. can you guys help me out? i need ammo for switching over. || dhcp reservation is best beacause you can make changes from a centralized spot and makes troubleshooting easier. ive never seen dhcp go down either. || imo dhcp. if necessary one can give it a static assignment with a long lease time to bridge over any dhcp outage other than the device rebooting. || dhcp as you will never need a tech physically onsite to do anything other than plug the device into the wall"
firewall best practices,"any suggestions on good udemy courses to enhance firewall knowledge with labs. i have tried a couple but have run into all sorts of problems getting labs set up and have wasted hours of my time. anybody know any simple lab setups to practice? || it depends on which firewall vendor you like to study. each vendors have their own unique gui and their own cli syntax. there is no vendor neutral firewall, basically one firewall for all. i would say you should go for fortinet, their fortigate firewall is widely used across the world and youll definitely will get your hands on these firewalls. they have free online training courses at you just need to create a free account and thats it, only thing that cost will be the certification if that is your intent. also, fortinet have plenty of available content pdfs on their website. ill be though honest that i find their online training being not that detailed and youll find yourself googlingwatching youtube videos as well just to get a better grasp but this goes probably for every vendor. || fortinet has a lot of free training out there for their cert programs. i would start with that."
firewall best practices,"hey everyone, im a firstyear undergrad currently doing a research internship focused on wireless sensor networks wsns. my professor assigned me a project to replicate and then optimize the results of a recent ieee paper titled deep reinforcement learning resource allocation in wireless sensor networks with energy harvesting and swipt. ive implemented the custom wsn environment along with dqn and actorcritic models. after tuning and debugging, my loss convergence and throughput results are pretty close to the paper, but not identical yet. the main challenge now is deciding whether this level of replication is solid enough to start experimenting with new methods like ppo, sac, or better baselines, or if i should first aim to match the original figures more precisely. has anyone here worked on similar drl wsn projects? would love some insight on how closely replication results should match before moving to improvements tips for improving throughput without breaking convergence any best practices for comparing rl agents to baselines in these types of setups thanks in advance! happy to share coderesults if helpful. || "
firewall best practices,"hey everyone, with two of my friends, we wanted to set up a shared subnet across our three homelabs, each in a different physical location. to do this, we used our existing infrastructure with proxmox and opnsense. i followed the vxlan bridge guide from the official opnsense documentation for the underlay, i decided to go with wireguard which ive been using for years and set up the vteps just like in the tutorial. at first, for a proof of concept, i just wanted to route the network between our three sites using vni 15. between two sites, everything worked perfectly. i set the mtu of my wireguard interfaces to 1600, as recommended in the opnsense forums, so that my bridges and vxlan interfaces could stay at 1500 mtu. that way, i didnt have to deal with custom mtus or tcp mss normalization issues. i also tested with dont fragment df flag across the internet, and mtu 1600 worked fine without fragmentation between the vtep interfaces of each site through the wireguard tunnel. but when i tried adding the third site, things got complicated. initially, i set up one wireguard interface per site with two peers one for each of the other two sites. then, on each firewall, i created two vxlan interfaces site 1 vxlan1 for vtepsite1 to vtepsite2 vxlan2 for vtepsite1 to vtepsite3 site 2 vxlan1 for vtepsite2 to vtepsite1 vxlan2 for vtepsite2 to vtepsite3 site 3 vxlan1 for vtepsite3 to vtepsite1 vxlan2 for vtepsite3 to vtepsite2 but then i hit a limitation in unicast mode as described in the opnsense guide, i cant use the same vni 15 on two vxlan interfaces. i get this error network identifier x already exists in this socket this caused some really weird behavior fw1 can communicate with fw2 and fw3 fw2 and fw3 cant communicate with each other over vxlan to fix this, i had to do something a bit weird with network bridges by assigning different vni ids per pair of sites fw1 to fw2 vni 15 fw1 to fw3 vni 16 fw2 to fw3 vni 17 i know this is not a standard vxlan setup at all, but its the only solution i found for now ive never done vxlan before . so, on each firewall, i now have a network bridge bridge0 that links the two vxlan interfaces and the physical nic fw1 bridge0 fw2 bridge0 fw3 bridge0 right now, this works, but im starting to realize its not maintainable at all. if i want to transport other networks like 10.8.16.024, 10.8.17.024, 10.8.18.024, id have to either create at least 3 new interfaces on each opnsense firewall 2 vxlan interfaces 1 nicvlan and another bridge. or create vlans on bridge0, but as far as i know, opnsense doesnt support vlans on a bridge interface. or use vxlans native vlan transport, but i dont really know how to do that on opnsense. i looked into multicast vxlan, which seems like the perfect solution for my use case, but wireguard doesnt support multicast, so thats not an option. id really like to avoid using ipsec if possible. so now im trying to figure out the best way to design this network so that its functional reliable fault tolerant and easy to monitor maintainable without adding too much complexity if i want to add a new subnet and ideally performant we have great fiber network it should be great to use it if anyone has experience with vxlan on opnsense or a similar setup, id love to hear your thoughts! im open to discussions about every part of my setup. thanks for your help! || functional reliable fault tolerant and easy to monitor maintainable without adding too much complexity if i want to add a new subnet and ideally performant we have great fiber network it should be great to use it honestly? abandon layer 2 and go for layer 3. then run bgp with your friends and you can exchange routes. everything is better at layer 3. if you are crazy enough to do layer 2, ideally your opnsense should not have any vxlan configuration on it. usually only the endpoints of a vxlan network here proxmox are aware of the layer 2 vxlan aspect, and all the nodes in the middle here opnsense and wireguard only see a plain layer 3 udp packet. || this boils down to how do you extend l2 between sites which is a question that engineers have been trying to answer for 20 years. the right answer is dont. the fun answer is vxlan like you want to do. the easy and expensive answer is metroe. the cluster fuck answer is routing individual hosts between sites and have a hub site. the hacky answer is mpls over gres. but seriously, if you arent familiar with vxlan, let alone a dynamic protocol for an underlay just avoid it and do layer 3. it saves a lot of heartache especially if you dont get any benefit from extending l2. || im a big vxlan guy. probably setup a dozen very large ip fabrics in my time. but it works best as a lan tool, low latency, with many paths supported by a layer 3 underlay. for your use case you are over complicating what you need. just go l3. vxlan isnt meant to bridge a broadcast domain over the wan."
