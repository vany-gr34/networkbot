mot_cl√©,post_et_reponses
grafana network dashboards,"edit found the issue, see comments. hi network experts, i am a jackofall trades, master of none. if my assumptions or plans are stupid, please tell me. i currently have a network with 200 hosts, simple local ad, hyperv, no complicated stuff. we recently purchased a sns220. my current plan is to set it up between our current router and the internal network. in the current setup, i have where all my hosts reside in. this network is connected directly to our consumergrade yeah, i know router, which provides internet connection via our public 30. now, i would like to set up the stormshield in between as a first step in the right direction internal network stormshield router. in the long term, i am also planning to switch ip ranges, implement some vlans and use more subnets. my test implementation currently looks like this host 10.0.0.24 stormshield port 2 10.0.0.254 stormshield port 1 192.168.10.18 router 192.168.10.1 however, for some reason, i can not reach anywhere behind the stormshield from my test host. i configured the ip addresses for the stormshield directly on the interfaces, not using a bridge. both interfaces are set to internal protected. then, i set the nat filter preset to 4 low and disabled the vulnerability manager. all packages from my test host to anywhere on the or the internet seem to disappear in a black hole, and i cant find any reason for it. also, the dashboard logs a lot of issues called ip address spoofing type1, describing blocked packages, where the source is the stormshield itself and the destination are stormshield update and telemetry servers. i guess i am just missing a small piece of configuration somewhere, but i cant find out what or where this is. can anyone here give me a hint or some tips please? || i found the issue. first of all, my interface 1 needed to be set to external public instead of internal protected. second, i needed a nat rule which translated the source address."
grafana network dashboards,"hey folks, my company is in the process of implementing thousandeyes, and im new to the tool. ive gone through the documentation and understand there are different types of tests like http server, page load, network, dns, etc., but im trying to get a clearer picture for a realworld use case. my manager has asked me to explain how we can effectively utilize thousandeyes in our environment cisco sdwan , webex contact center beyond just running basic tests. were mostly interested in improving visibility and troubleshooting for network and application performance, but im not sure what the best practices are, or how others are leveraging it daytoday. would appreciate if anyone can share common use cases in your organization what tests you rely on the most any tips or gotchas for managingautomating alerts or dashboards things you wish youd known when getting started || thousandeyes falls in to the category of products known as digital experience monitoring. rum real user monitoring is fulfilled by endpoint agents, a lightweight agent gathering statistical performance data from your enduser laptops desktops. the cloud enterprise agents perform synthetic transaction monitoring the endpoint agents have a very limited set of stm tests they can also run. these are the network, dns, etc., tests that you referred to. rum is great as a triage tool. when joe calls the helpdesk and says i had a terrible webex call, the endpoint data can point to causes like high cpu, poor firsthop performance, bad wifi signal, etc.. this affords helpdesk the visibility to close tickets before they go up to more advanced engineers responsible for client engineering, networking, app owners, you get the idea. synthetic tests are best used to evaluate either critical services, or, critical network paths. think about a sla attached to a customerfacing biz app. you may want to run synthetic tests from a combination of cloud, endpoint, and enterprise agents, to effectively measure your service availability latency. i would try to pick agents that best represent the locations of your users. if your apps are primarily you can validate that not only is the socket open, but that you are getting back the correct http response code or script for more advanced web workflows. otherwise you fake it with an agenttoserver test and point to the appropriate combination of protocol port, you just wont negotiate an actual session. you may also want to run agenttoagent synthetic tests to validate critical network paths. this could be sitetosite, sitetocloud, or even within a dc or lan. this could leverage a combo of enterprise and cloud agents as needed. id start by making a list of critical services, critical users, and frequent problem areas. build your tests around that and see what you learn. as others have mentioned, their licenses are big money, and you want to maximize the value. engage your cisco account team as they will be thrilled to help you get set up the more you succeed, the more likely leadership will want to buy more, so theyre incentivized. btw... this does not replace traditional flow and packet based performance monitoring. || depends on your budget hoe much monitoring you can enable. or.. tokens || te is very overpriced for most folks if you are just going to pinghttp test from your branches, there is free software that can do this. also note they charge you per test, despite your enterprise agents running on your hardware. if you rely on a lot of internetbased apps, it can be very helpful, or if you dont have smokeping or something already. || for sdwan monitoring, then you can set up tests on the overlay, then tests for the underlay and program the sdwan to drop the underlay test packets down. for webex, there are two things you may want to monitor. on the enterprise agents, set up an agent to agent test from your enterprise agents to the webex cloud agent that your site will probably communicate with. then for your endpoint agents, enable the on demand test for webex for any other application it depends on the application and how the application works. || im a var and helped a few clients stand up thousandeyes for sdwan visibility and app performance, especially around things like webex, salesforce, and o365. the most useful tests have been continuous http server tests for saas monitoring, bgp path visualization, and endpoint agents for branchtocloud visibility. dashboards and alerting take a bit of finetuning early on, especially if you want to avoid noise. shoot me a dm if you want more infosupport! || you need to make sure your agents are deployed in the right locations. can be deployed in the right locations and you have a good story around updating and patching them. without going into very specific tests the 1 minute agent to agent tests are pretty good. they open a tcp stream and spread packets throughout that 1 minute window giving good data on latency, packet loss etc once agents are deployed everything else can be configured. enterprise agents to cloud providers, custom tests, whatever. te has a good terraform provider, its a nice easy way to turn tests offon, save on credits, document the tests for future reference and learn a new skill in the process. || were a cisco shop and we upgraded our network recently so we got a ton of te entitlements. im honestly not finding it very useful. there have been a handful of cases where an endpoint agent would have been nice to have but we were told the minimum you can buy is 100. wed probably only ever use 5 at once so theres no way wed pay tens of thousands for access to the endpoint agents. otherwise the only real use i got out of it was setting up a bgp monitor in our network which allows me to see what as hops a packet will take. not useful at all but interesting to know. not a very helpful comment but id figure id share. edit endpoint agent, not enterprise. || disclaimer i am not from ciscothousandeyes. i am just one of their happy customers. i share some details below, which are my personal opinion. under the hood it uses common troubleshooting tools like ping, traceroute, curl, dig, etc. in a way it is nothing new or can be replicated easily. real strong points of thousandeyes 1 if you use have 90 cisco gear in your environment, you can deploy an agent on supported cisco devices almost anywhere. we have a few agents at each branch sites. it is that simple to install. the agents are quite stable. common issues i have seen is the hosting hardware failing or internet thousandeyes is saas so ... acting up. 2 cloud agents. these are enterprise agents but hosted by te. this is really good as it gives you the option to probe from the internet. you can use it to probe other stuff in the internet or maybe a public facing enterprise resource. 3 ability to do ad hoc probes from hundreds of agents. very nice for troubleshooting. 4 if you set up ongoing tests, you have historical data on what you are probing for up to 2 months. very useful or rcas or to proof that the issue was not on network side. 5 gui is nice and easy to navigate. support is excellent. i personally rank them higher than tac and meraki support. success stories 1 identifying exactly a routing point of failure in isp upstream and having isp to change the design for that particular link. 2 application monitoring. you will be surprised with what this can pick up, from server issues to dns issues to dns routing issues and of course network issues. cons 1 it is very expensive. 2 its value is only as good as the usecase you can come up with. what you should note 1 since thousandeyes uses icmp amongst others under the hood, check with your security guys if they allow such traffic. if they dont then you lose like 30 of the value from no path visualization data. 2 think hard about your usecases. while i am happy with thousandeyes, i admit that it is not the solution to everything and there are usually simpler cheaper alternatives out there. hope this helps."
grafana network dashboards,"network architecture at akamai defines our role in the global internet and drives backbonerelated strategic decisions.you will be responsible for designing and developing systems to improve our ability to operate akamais global backbone selecting and integrating third party software into our ecosystem when appropriate contributing to and advocating for an agile development culture within akamai do what you loveto be successful in this role you will have full stack programming experience, focused on python with experience in javascript and html have experience with devops practices ability to maintain software stacks and develop them to be scalable understand cloud deployment strategies and modern service orchestration such as containers, distributed storage and kubernetes have experience with network telemetry software stacks, including metric agents, timeseries databases, dashboarding and alerting have knowledge of general internet network operations including those of internet and network service providers || whats weird about it? seems a bit vague for sure but doesnt strike me as that odd. they are a huge cloudprovider. || no. seems like typical responsibility for a networking team at a hyperscaler. || akamais being doing devnetops before it was even a thing. same skills as any other faang type gig. || looks pretty fine to me. akami is a huge global cdn company, sounds pretty normal || its probably a more handson architecture role. given their experience in automation of global networks, this would jive with that. || seems legit and not weird at all. theyre a monster company and getting to granular would create a job ad the length of war and peace. || it can be seen as weird in the sense that there is not much networking there, its a sysadmin software integration job."
grafana network dashboards,"i have joined a new company where we will be deploying around 300 routers with a sdn controller. i havent worked on service assurance for many years and now i need to look at a new solution. i worked on ibm netcool many years ago on a noc of 50 people managing a big telco network. i was wondering what are the new monitoring platforms. does grafana allows managing alarms like in netcool acknowledge, manually clear...etc alarms like in netcool. thanks for sharing any tips for pro and cons. || it really depends on many things. budget, needs, and team ability to use the tool are all important. we semirecently did a pov between a bunch of providers. my personal favorite was datadog, but we went with logicmonitor. anyway you go, i would suggest a cloud console as youre eventually going to need an overlay and isolation strategy given the state of the industry. || depending on the manufacturer of the router the use of liveactions livenx would make sense || maybe you should read up on modern monitoring theory first before trying to apply oldschool thinking to a greenfield deployment. || would love to talk to you about your monitoring needs, i also worked on a large ibm netcool project long ago. im currently the lead developer of an opensource tool called serviceradar, which might fit the bill for you. if you want to chat please reach out to me, or have a look for yourself at and be sure to check out the live demo site as well at || zabbix"
grafana network dashboards,"i normally handle desktop support at my company, but this one has gotten me stumped. there are some users in office a that connect to an ap inside of their office, lets call it apa. next door, in another building about 20 feet away is another office, office b. office b has an ap called apb. both offices use mr33 aps and broadcast the same ssid on our corporate network. for some reason, some users windows machines in office a prefer to connect to the ap in office b. it tends to bounce back and forth for them, with each time that it roams causing a brief disconnect. here is what i have done to try and troubleshoot 1. update wifi drivers. 2. reimage completely the laptops that were having the issue 3. change wifi driver settings to tweak the roaming aggressiveness. setting it to 1 only made it stick to the weak signal on apb and putting it to 5 made it bounce back and forth more frequently here is a screenshot of some of the roaming shown in meraki dashboard for one of the users. note that the laptop is connecting to apb even though it has a weaker rssi and snr. our network administrators insist that the meraki aps arent the problem and that it is a client issue, but i wanted to get your input to see if there was anything else that i can try on my end as desktop support. || im not super familiar with the meraki dash but it looks like its saying multiple roams took full seconds. that to me says you have a communication issue between the aps. i had semi similar behavior happen to me once when i was trying to test a new model and forgot to change the switch ports to be in my normal wap management vlan. roaming requires the aps to share session and mac tables to facilitate the handoff. most companies do this in some kind of layer 2 protocol so its important they be in the same vlan. generally that vlan is only set in config since ap ports are also trunk ports but in my case i had plugged into two user ports on different vlans. the behavior i saw was similar to what you described, the clients seemed to favor a specific ap and wouldnt roam as long as they could hear it. || it could be a client issue. im missing some really important details on the clients. make, model, os and most important, what wifi card? make and chipset. the wifi team needs to have this information as well. they cant say theres no issue without looking at the whole chain. wifi troubleshooting is a lot more complex than wired. || first things id look at are is client balancing enabled on the ssid? txpower range on the ssid range or fixed value 2.4 andor 5 ghz bands in use? aps in same vlan? id stray from tweaking driver settings for roaming as you shouldnt need to and its way more hassle to keep up with if you change your ap infra or settings in future. || not a wireless expert by any means here so take the following how you will.. there is a lot of heavy lifting of wireless roaming that stems from what the supplicants clients support. each brand device has different wireless technologies they usesupport. from my experience macs tend to hold on to signal till its almost unusable till they finally let go and then can connect to another better ap. we definitely have had some better luck with windows. a big benefit we got was just fully disabling the 2.4g band completely and only supporting 5 as we noticed some clients bouncing between for whatever reason. we ade a few more tweaks to signal strength to try to not onload clients past a certain signal strength dependant on layout. if push comes to shove you might need to make some test cases out of business hours and play around till you figure out. or bring in an expert. || had this same issue recently with meraki. first completely disable each ap and retest just to make sure it isnt an ap configuration issue. after that try the following create a new rf profile that does the following reduce channel width on 5ghz to 20mhz reduce power level on 2.4ghz and maybe 5ghz disable client load balancing. also try flipping 802.11r. if its off turn it on or to adaptive mode."
grafana network dashboards,"anyone using nexus dashboard to manage their network entirely? including the deployment of a vxlan fabric from scratch? seems pretty easy to use but curious what other people think and how large scale deployments have gone with it. would love to hear stories and opinions good or bad. once you deploy the fabric i suppose im stuck using nd forever now and cant really make any manual changes outside of it? other than maybe ansible controlling and scripting for nd. thanks! || using it just fine for multiple datacenter fabrics. also used it great for a multipod poc with a centralized super spine fabric. || with how many times cisco has changed the management product for nexus fabrics i literally bought fabric manager and my account team called me a week after it was delivered to tell me they eold it, i wouldnt bother. look at something like apstra and be happier that they wont rug pull you in the future || we have very active changes in our fabric, fabric changes every 510 minutes, and its terrible for our use case. if you have a more static fabric then i would highly recommend it. its pretty solid besides that and support has been at least okay so far. || i would try to de couple from cisco nm and get some ansible going. if you are doing any refresh soon then look into arista. || i have multiple deployments of fabric controller with fabrics between 30 and 80 leafs. the software has improved in later versions but the upgrade process is hit or miss often failing so this is a big negative and has caused a few long shifts rebuild after failed upgrades. making changes is straightforward, but if multiple people are making changes or dont deploy the changes they make them sometimes you dont know what they are for or whether they should be deployed. theres a new change management feature in 3.2 which should help with this. if you make a change through cli then fabric controller will try and reverse that change so its not advisable. || juniper apstra for a pure vendor agnostic experience to design and deploy in minutes! i suggest looking into it || we are using it now for a few new depolyments, so faar so good. not sure why people are suggesting vendor agnostic datacenter fabrics, sounds like an awful idea specially with the history of vxlan interoperability between vendors has been really bad, only one i have heard does it decently is aristas clous vision with nexus arista switches. just do yourself a favor pick one and stick to it would be my advise. i have not used arista my self but few buddies of mine have and they talk foundly of it. i have used cisco mostly in datacenter and it has been very stable. || it is useful to deploy vxlan on multi sites fabrics. all other features are full of bugs and limitations. cisco has built a tool for their typical deployments. if you need to have adaptations that go out of their dream design, you will have some problems. examples pbr with firewalls, fqdn not supported for ntp and syslogs, external, bgp passwords and bfd on external connexions || imho vxlan is simple enough on its own. you dont need an extra product to manage it. vni settings, replication settings, bgp. all very basic configs and easily automated and synced between leafspines across your fabrics using your automated tooling of choice. || none of those tools are ever kept up to date with the software versions they are managing. its been a clown show going all the way back to ciscos phone systems to the gsr routers. its best to be very familiar with the cli || it is a buggy and slow piece of shit dont do it, you will never have a fabric in sync"
grafana network dashboards,"hey guys. i rent a dedicated server for some projects with one ipv4 ip that, due to the nature of my projects, is exposed and not behind any sort of cloudflare proxy. recently, some skript kiddie messaged me on discord that he downed my entire network. sure enough, he did. contacted my antiddos provider royalehosting and they say they cant detect anything on their end. well anyway i set up something similar to to dump pcap files to send to my provider. got hit again, then once the server came back online i downloaded the pcap files and sent them to my provider. of course, they said the provided packet captures do not seem to indicate an attack. bruh. since then ive installed netdata and spun up a cloudflare zero trust tunnel so the system can be monitored and i can just send them the url to the netdata dashboard. 1. how can ddos attacks just completely bypass an antiddos provider, and is this provider just completely trash or could they really not detect it? how do attackers mask their attacks? 2. is there anything else i can do to prove to these nincompoops that my server was indeed taken offline? for context, we had 100 packet loss, and my ssh connections were blocked for hours. all web deployments were unreachable as well. 3. should i drop these guys for their incompetence? 4. since the botnet was chinese, is there anyway to just deny all traffic from china entirely, like with iptables? or is that a pointless operation? i am no expert in networking, just a humble selftaught sysadmin running my own projects. thanks for any insights you guys can provide. || cloud flare proxy wont stop a ddos attack towards an ip if the attacker knows the real public ip. cloud flare hosts your dns, provides a new public ip to hide the true public ip behind and force all traffic destined to the fqdn through its system. but if they arent attacking the fqdn, the traffic wont go through cloudflare. ask your isp to change your public ip, make sure there is nothing announcing dns for the new ip. setup cloudflare dns so that the cloudflare proxy forwards traffic to the new ip. || are you showing an increase in network traffic during the outages? if yes, probable ddos. if no, probably something cleverermake sure your system and all software are up to date. there are databases of ip address geolocation maxmind is a well known one, where you can create a rule to deny all traffic from addresses listed as being in china hong kong, etc.. results vary. ||  || what do the pcaps show? a ddos isnt the only thing that could break connectivity, and not all such attacks would be visible on the targeted server. did the script kiddie indicate how he was intending to attack the server? || since the botnet was chinese, is there anyway to just deny all traffic from china entirely, like with iptables? or is that a pointless operation? you can do that, but if theyre saturating your connection, youll have to do that further upstream."
grafana network dashboards,"hey everyone, i run a shortterm rental business with about 180 properties, and were looking to optimize our guest wifi setup to save costs and improve control. right now, we use ubiquiti aps and pay stayfi a hefty monthly fee 1,000 for a captive portal that collects guest info name, email, phone before granting internet access since airbnb doesnt share this info with us anymore. we want to ditch stayfi and build a custom captive portal hosted on our own website to collect guest info name, email, phone and store it in google sheets or airtable. boost website traffic seo by hosting the portal on our domain. standardize the portal across all properties, whether using ubiquiti aps or ispprovided modemrouter combos. our current setup guest network captive portal enabled uses ubiquiti aps, currently managed by stayfi. admin network no portal dedicated to smart home devices tvs, thermostats, etc.. new ispprovided equipment some properties have adtran 8546 routermodem combos. the new fiber isp is open to configuring them to support a captive portal and working with us directly, but we need to confirm feasibility. what were trying to do reconfigure ubiquiti aps to redirect guests to a portal on our own domain instead of stayfi. configure ispprovided adtran 8546 routers to do the same to avoid extra ubiquiti aps at new properties. automatically store guest data in google sheets or airtable for marketing crm use. set up a dashboard to monitor all networks, detect outages, and manage device health ideally via unifi or another tool. questions we have 1. has anyone successfully configured a captive portal on an adtran 8546? does it allow custom redirects, or do isps typically lock this down? 2. whats the best way to set up a captive portal that works across both ubiquiti aps isp hardware? any software recommendations? 3. whats a good monitoring tool for tracking all networks devices in one place? wed love to be able to connect it with some automation to automatically sms or message the guest when they unplug wifi equipment for who knows what reason.... and then complain the wifi isnt working. 4. any pitfalls we should watch out for when implementing this at scale? any thoughts? if youve done something similar or have any insights, id love to hear your advice. thanks in advance! || yuck. people expect wifi to be free and not scrape their details in the year of our lord 2025 ad. high friction wifi sucks. storing peoples pii in google sheets is gross. || lost me at google sheets. || how about hiring a fing network consultant?"
grafana network dashboards,"hi guys, just wondering what dashboards any of you have created on grafana in a cisco environment that you found particularly useful? || true happiness comes from building dashboards that give executives deeper insight into critical business functions || the main advice i give to firsttime dashboarding folks is this dont create mega dashboards. a dashboard should have maybe 1015 panels max and only scroll to two screen pages. if your dashboard has dozens and dozens or hundreds of panels, many rows, youre making an unusable mess. breakdown the dashboards into individual useful views. main system overview datacenter hvac status datacenter upspower status device hardware status details device traffic overview port traffic detail make a dashboard targeted to doing one type of view. organize them with links to each other. this also helps future you by allowing you to write alerts that have dashboard links that you can link to detailed debugging, without a lot of cluttter. you can use url param variables to fill in exactly what the operator needs to debug. switch temp alert? you can include a dashboard link in your alert template with all the datacenterrackdevice vars prefilled so you can see the hardware details with a link to datacenter hvac status dashboard in case nothing in the device looks wrong. || visualising shit. ive used it for quick look at port utilisation all the way through to power management across pdus and phasescircuits in the building because they were my needs. id start by asking what information is useful but hard to obtain today and work out how to visualise it. || only you can answer this question. what is it you like to see that you cantdont see today? do you have any pain points in your environment you would like to look at? do you have a noc? everyones environment is different so everyones use case will be different. my dashboard wont necessarily be useful to you whereas somebody elses might. without knowing anything about your environment, slightly difficult to suggest anything. || anything that you want to bring different data sets together. want to show a device with syslog and snmp? now you can. looking at an edge router? bring together those two plus enriched netflow. now you see the health of the box, any logs, and top 10 talkers all in one dashboard. have something checking hardware and software end of life? put that on the dashboard too. what about the last time a configuration change was made? or just even if running golden config. theres so much data we go through and theyre all in these different toolsets. grafana allows you to bring them together in interesting ways so you can correlate or rule out that data during those stressful outages. || can pair it with prometheus || i have a couple of scripts that pull information from 9800 wireless lan controllers and generate graphs showing client wifi performance rssi and snr and ap stats. i have another that lets me see switch port stats utilization, total errors, drops in one view || interface traffic, interface errors, optic light levels etc basically anything you want to, if you have the data to hand. || we have multiple dashboard groups remote access vpns ipsec vpns firewalls load balancers network in each of them we have multiple dashboards. for example remote access vpn types such ad openvpn, anyconnect, etc will show you number of connected users remote access vpn sessions devices server utilization || we are using for bandwidth utilisations monitoring in some area also the internet utilisation || less is more. first i wanted all in one dashboard, but now i preffer more dashboards with specific info, just a few panels and filter by devices, or many panels with the same metric at different points to compare. and of course ive got a dashboard with all the info that my director wants. || up down"
grafana network dashboards,"my title is network security admin, and i make a 55k salary in an hcol area. a typical day is as follows we have firewalls and other devices installed at about 300 client sites that i monitor in the ubiquiti dashboard if a site goes down, i first call the isp we have set up for that location and see if a simple reboot will fix the problem. if they cant see any equipment, ill have them dispatch one of their techs. otherwise, ill make a ticket for myself, then dispatch to the site and try to fix the problem. usually, its a layer 1 problem or a configuration issue that one of the less experienced techs caused, but sometimes it can be layer 3 or 4. occasionally, we have firewalls with consistent issues, and i need to read logs to determine whats going on. when i joined this company, they didnt have their firewalls configured correctly. by default, they were allowing all traffic through. so, i created a syslog server and pointed all our firewalls to it. my syslog server identified hundreds of thousands of ssh attacks daily which explains why our sites were constantly going down, so i updated the configurations and pushed them to all of our sites with an ansible script. we also had an incident a year ago where a client needed us to download footage from a specific period, but we couldnt because the nvr had gone down, and we didnt even know. so, now im in the process of trying to create a solution that will notify us when a port goes down. sometimes, on my dispatches, ill engage with clients and try to identify opportunities for network upgrades. ill do a site survey and then provide them with a quote. for example, i went to fix this property managment companys wifi from an old it company, and i guess i impressed the lady running things enough to convince her to upgrade their wlan with our equipment. i did a site survey with her, explaining how we could implement it and how much it would cost. we then sent her a proposal the next day, and she signed it. i came back to install everything. ive only been in the industry for about 1.5 years, but sometimes i feel like i wear a lot of hats, and i dont know if im being adequately compensated. || youre seriously, significantly underpaid. however, this is a very rough time to be looking for a new job, so tread carefully. || immediately no. || read the first sentence. no, you are not getting paid enough. || your company is saving a boatload of money at your expense. || noone here is giving you exaggerated advice. they are absolutely right when they say you deserve 85k at bare minimum. dont feel bad either about leaving your position and you end up leaving your company in a difficult situation. if they decided you needed to get laid off, they could care less about your problems. even if this company you work at attempted to match an offer from a new job, deny it with no hesitation. ||  || salary for a network admin will vary wildly depending on where you are. in a high cost of living area i would think around 100k. in a low cost if living area 60k. that will also change on where you are. are you in an area with a glut of network admin and a few jobs. i think we start network admin at 60k to 75k, but we are in a very low cost of living area. we used to be way lower but all the network admin and engineers in our area completely changed companies one year. one guy quit for a state job, another was hired away from one company for a higher salary, and so forth. in the end a half dozen of us all switched jobs or got very big raises all in about a year. || omg update your resume and start applying asap. in a hcol area you probably can get double your salary. || if this is your first job then no. but you should use this as a stepping stone and start looking for jobs now. || theres exactly one way to find out go to the market and test your worth. apply for jobs and see what you get. || at 1.5 years you can ask for a payperformance review. if they dont give one then start looking. loyalty works both ways. if they arent prepared to review your pay then you know where they stand and can feel no guilt for looking for another role elsewhere. its good to change company and role every now and then so get get a well rounded understanding of how different systems work. || a no b theres a lot here you can automate with a nms if you want to stay and do less manual work. librenms free nms can monitor all your firewalls and with some config, associate each to their isp and automatically email them if they go down with a template asking them to reboot. you shouldnt have to manually check a dashboard, just get told via mails or teams or slack or whatever if a device drops. librenns can also tell you if a port goes down or if a device stops pinging and youd know if the nvr is down immediately. implement this, add to your resume and get a much better paying job. || i saw ubiquiti and 55k in the same paragraph and thought thats about right joking aside, you sound underpaid but salary goes hand in hand with years of experience, skills and whatever the job thinks youre worth. if you think you are worth more then the ball is in your court to pitch your wares to other employers for more money. || if you are working for a company using ubiquiti as their primary equipment, you should never expect more than your getting. they dont want to be serious about their hardware investment, they definitely dont want to be serious about their employee investment. access control companies get by paying their normal staff shit wages and convince them there isnt much better. dont get sucked into it. look for network admin jobs, network engineer, etc, whatever interests you. msps will also tend to rape you and run you into the ground, but not all. theyre good for learning though. i agree with nearly all other comments though. you need to look around. however, dont take to heart the shit everyone says about needing to jump every 3 years to increase salary. ive been in the it since 2004, and have spent an average of 7 years at each company ive been at, some more, some less. after my first it job, i got recruited for every position after that. each of those jobs i usually ended my employment making 2030 more in the same role than when i started. the change of jobs usually netted me an additional 2030 increase. if you bust your ass, network with people, learn everything you can, and get good in a specialty area generalists never make at much as those who specialize, you can definitely make bank. i know this isnt universal, but in my experience the only people that had to job hop every 23 years were the ones that couldnt sell their value any higher and had to swoon in job interviews. keep in mind, ive always been very picky on who i work for, and made those job decisive accordingly. until you build a professional network, its more difficult to interview your prospective employer as much as theyre interviewing you, but that should be your goal in job searching. its always better to have someone you know come and ask you to work for them unsolicited. sorry, no advice on the girlfriend wanting 5 kids and a big house. tell her she needs a raise too i guess haha. || my sense is that with your skills, experience and proof of your work ethic you should be able to fetch about 115k or higher in a hcol area."
